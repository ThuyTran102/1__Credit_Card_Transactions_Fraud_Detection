{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da7e6a9-6bbd-4773-95ea-f579bc6aa743",
   "metadata": {},
   "source": [
    "# Credit Card Transactions Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca39e00-794b-41ca-9d07-e3af6cb32731",
   "metadata": {},
   "source": [
    "## **Part III:** Model Selection\n",
    "**Table of contents:**\n",
    "\n",
    "1. Metric Consideration\n",
    "2. Import libraries\n",
    "3. Load data\n",
    "4. Implement **baseline** models on **Full Feature Set** with:\n",
    "    >-   Logistic Regression\n",
    "    >-   Support Vector Classifier (SVC)\n",
    "    >-   Gaussian Naive Bayes (GaussianNB)\n",
    "    >-   Random Forest Classifier\n",
    "    >-   K-Nearest Neighbors Classifier\n",
    "    >-   AdaBoost Classifier\n",
    "    >-   Gradient Boosting Classifier\n",
    "    >-   XGBoost\n",
    "    >-   Bagging Classifier\n",
    "\n",
    "5. Re-train **baseline models** on **Important Feature Subset**.\n",
    "   - 5.1. Try subset of 13 features (exclude 'city')\n",
    "   - 5.2. Try subset of 12 features (exclude 'city' and 'state')\n",
    "   - 5.3. Try subset of 7 features\n",
    "   - 5.4. Try subset of 6 features\n",
    "   - 5.5. Try subset of 11 features (exclude 'state','day of month','distance')\n",
    "     \n",
    "6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c5662c-c8ca-4413-9bd1-c84456ff9d8e",
   "metadata": {},
   "source": [
    "# 1. Metric Consideration\n",
    "- Accuracy metric is not suitable for fraud detection because the data is highly imbalanced. A model can achieve high accuracy by simply predicting the majority class (legitimate transactions), but this does not mean it effectively detects fraud. Metrics like precision, recall, and F1 score are better as they focus on the minority class (fraudulent transactions). Moreover, we want to focus on fraud detection, so general accuracy is not a best choise in this case. We should use `Precision`/`Recall`/`F1 Score` instead of Accuracy.\n",
    "\n",
    "- In fraud detection, the importance of `Precision` metric versus `Recall` metric depends on the specific context and the consequences of `false positives` versus `false negatives`. Here’s a breakdown to help you understand which metric might be more critical:\n",
    "\n",
    ">#### 1. Precision:\n",
    ">- Definition: Precision is the **ratio of true positives to the total number of predicted positives**. It measures the accuracy of the positive predictions.\n",
    ">- Importance in Fraud Detection: High precision means that when the model predicts a transaction is fraudulent, it is likely to be correct. This is **crucial if the cost of investigating a false positive** (a legitimate transaction flagged as fraud) is high. High precision is important when:\n",
    "    - Investigations are costly and resource-intensive.\n",
    "    - **Customer experience is a priority, and false positives could lead to customer dissatisfaction.**\n",
    "    - The system is used in a real-time setting where immediate actions (like blocking transactions) are taken based on predictions.\n",
    " \n",
    ">#### 2. Recall:\n",
    ">- Definition: Recall is the **ratio of true positives to the total number of actual positives**. It measures the model’s ability to identify all relevant cases within a dataset.\n",
    ">- Importance in Fraud Detection: High recall means that the model identifies most of the fraudulent transactions, reducing the number of missed fraud cases (false negatives). High recall is important when:\n",
    "    - The cost of a missed fraudulent transaction is high.\n",
    "    - The primary **goal is** to **detect as many fraudulent transactions as possible**, **even** at the **expense of some false positives**.\n",
    "    - Fraudulent activities have severe financial/law or legal consequences.\n",
    "\n",
    ">#### 3. Balancing Precision and Recall:\n",
    ">- F1 Score: The F1 score is the **harmonic** mean of precision and recall and provides a single metric that balances both concerns. It is useful when you need a balance between precision and recall.\n",
    ">- Context-Specific: In many cases, a balanced approach is taken, where the F1 score or a combination of precision and recall is optimized. However, the specific business context and risk tolerance will dictate the priority.\n",
    "\n",
    "\n",
    "### Practical Considerations:\n",
    "- **If the cost of `false negatives` (missed fraud/positive) is high: ----> Prioritize `recall`**. This is often the case in financial, law institutions or diagnosis of disease **where a missed fraud/positive can lead to significant losses**.\n",
    "- **If the cost of `false positives` (incorrectly flagged legitimate transactions) is high: ----> Prioritize `precision`**. This is common in scenarios where **customer satisfaction and experience are paramount**, and investigations are expensive.\n",
    "\n",
    "- In most fraud detection scenarios, recall tends to be slightly more important because the primary goal is to **catch as many fraudulent transactions as possible. However, a high false positive rate (low precision) can also be problematic, leading to customer dissatisfaction and operational inefficiencies. Therefore, a balanced approach, often evaluated using the **F1 score, is usually preferred**.\n",
    "\n",
    "===>  HOWEVER, this case is not law institutions or diagnosis of disease, and I suppose my bank want to prioritize customer satisfaction \n",
    "(don't want to inconvenience or cause trouble customers with transactions that aren't actually fraud). Therefore, in this project, `precision` metric is my first priority, and `f1 score` is my second priority in model evaluation even though I show all metrics for evaluation. \n",
    "\n",
    "Precision is chosen for fraud detection to minimize the negative impacts of false positives and ensure that flagged transactions are truly suspicious, thus optimizing resource use and maintaining customer trust."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5993e1d1-e1dd-4263-8c53-f145685308c1",
   "metadata": {},
   "source": [
    "# 2. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d7e2aa-36b4-4eb3-930c-9d3cadb15fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style='darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c7baf-311b-46d1-adbb-f739817e63dd",
   "metadata": {},
   "source": [
    "# 3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c0201f-6eee-43d0-bcc3-2d69f1fff830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Load data\n",
    "X_train = pd.read_csv('../data/X_train_full_features.csv')  \n",
    "X_test = pd.read_csv('../data/X_test_full_features.csv')    \n",
    "y_train = pd.read_csv('../data/y_train.csv')\n",
    "y_test = pd.read_csv('../data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683a9371-41d4-418d-889b-f9c4aeae7ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2062670, 14), (2062670, 1), (259335, 14), (259335, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape\n",
    "X_train.shape, y_train.shape,  X_test.shape,  y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b490ad8-9e2c-40f5-9ce2-1b13fe2e698e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame,\n",
       " pandas.core.frame.DataFrame,\n",
       " pandas.core.frame.DataFrame,\n",
       " pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check type\n",
    "type(X_train), type(y_train),  type(X_test),  type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3edf3159-750f-49d9-96fc-1ccad0bf049a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__amt</th>\n",
       "      <th>num__city_pop</th>\n",
       "      <th>num__transaction_hour</th>\n",
       "      <th>num__transaction_day_of_week</th>\n",
       "      <th>num__transaction_day_of_month</th>\n",
       "      <th>num__transaction_month</th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__distance</th>\n",
       "      <th>cat__category</th>\n",
       "      <th>cat__gender</th>\n",
       "      <th>cat__city</th>\n",
       "      <th>cat__state</th>\n",
       "      <th>cat__zip</th>\n",
       "      <th>cat__job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.118626</td>\n",
       "      <td>-0.293624</td>\n",
       "      <td>-1.438913</td>\n",
       "      <td>0.422626</td>\n",
       "      <td>-0.746609</td>\n",
       "      <td>0.543626</td>\n",
       "      <td>-1.037192</td>\n",
       "      <td>-1.525742</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>4.837929e-03</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>4.837929e-03</td>\n",
       "      <td>0.003657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.360128</td>\n",
       "      <td>-0.285489</td>\n",
       "      <td>0.908058</td>\n",
       "      <td>0.877514</td>\n",
       "      <td>1.518615</td>\n",
       "      <td>-0.041775</td>\n",
       "      <td>0.170654</td>\n",
       "      <td>-0.048473</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>2.222222e-03</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>4.426955e-03</td>\n",
       "      <td>0.007768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.672535</td>\n",
       "      <td>-0.293571</td>\n",
       "      <td>0.174629</td>\n",
       "      <td>1.332402</td>\n",
       "      <td>0.272742</td>\n",
       "      <td>0.543626</td>\n",
       "      <td>-0.634576</td>\n",
       "      <td>0.440885</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>3.794038e-03</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>2.825999e-03</td>\n",
       "      <td>0.006925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.169753</td>\n",
       "      <td>-0.293429</td>\n",
       "      <td>1.201429</td>\n",
       "      <td>-1.396925</td>\n",
       "      <td>-0.293564</td>\n",
       "      <td>-0.334476</td>\n",
       "      <td>0.400720</td>\n",
       "      <td>-0.574901</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>8.443908e-03</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>8.443908e-03</td>\n",
       "      <td>0.008444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.237244</td>\n",
       "      <td>-0.271659</td>\n",
       "      <td>0.174629</td>\n",
       "      <td>0.877514</td>\n",
       "      <td>0.159480</td>\n",
       "      <td>0.543626</td>\n",
       "      <td>-1.439807</td>\n",
       "      <td>1.286029</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>1.285382e-18</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>1.285382e-18</td>\n",
       "      <td>0.005465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__amt  num__city_pop  num__transaction_hour  \\\n",
       "0 -0.118626      -0.293624              -1.438913   \n",
       "1 -0.360128      -0.285489               0.908058   \n",
       "2  5.672535      -0.293571               0.174629   \n",
       "3 -0.169753      -0.293429               1.201429   \n",
       "4 -0.237244      -0.271659               0.174629   \n",
       "\n",
       "   num__transaction_day_of_week  num__transaction_day_of_month  \\\n",
       "0                      0.422626                      -0.746609   \n",
       "1                      0.877514                       1.518615   \n",
       "2                      1.332402                       0.272742   \n",
       "3                     -1.396925                      -0.293564   \n",
       "4                      0.877514                       0.159480   \n",
       "\n",
       "   num__transaction_month  num__age  num__distance  cat__category  \\\n",
       "0                0.543626 -1.037192      -1.525742       0.002916   \n",
       "1               -0.041775  0.170654      -0.048473       0.002508   \n",
       "2                0.543626 -0.634576       0.440885       0.007255   \n",
       "3               -0.334476  0.400720      -0.574901       0.001616   \n",
       "4                0.543626 -1.439807       1.286029       0.002508   \n",
       "\n",
       "   cat__gender     cat__city  cat__state      cat__zip  cat__job  \n",
       "0     0.005233  4.837929e-03    0.006652  4.837929e-03  0.003657  \n",
       "1     0.005233  2.222222e-03    0.005073  4.426955e-03  0.007768  \n",
       "2     0.005233  3.794038e-03    0.004935  2.825999e-03  0.006925  \n",
       "3     0.006459  8.443908e-03    0.005742  8.443908e-03  0.008444  \n",
       "4     0.005233  1.285382e-18    0.004803  1.285382e-18  0.005465  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f252a3d0-2b45-46b7-9894-049392e6a28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_fraud\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43c06d07-4594-4dfc-80bb-a62d8688e5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num__amt</th>\n",
       "      <th>num__city_pop</th>\n",
       "      <th>num__transaction_hour</th>\n",
       "      <th>num__transaction_day_of_week</th>\n",
       "      <th>num__transaction_day_of_month</th>\n",
       "      <th>num__transaction_month</th>\n",
       "      <th>num__age</th>\n",
       "      <th>num__distance</th>\n",
       "      <th>cat__category</th>\n",
       "      <th>cat__gender</th>\n",
       "      <th>cat__city</th>\n",
       "      <th>cat__state</th>\n",
       "      <th>cat__zip</th>\n",
       "      <th>cat__job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.405589</td>\n",
       "      <td>-0.287532</td>\n",
       "      <td>-1.438913</td>\n",
       "      <td>-0.487149</td>\n",
       "      <td>1.518615</td>\n",
       "      <td>-0.627176</td>\n",
       "      <td>1.148435</td>\n",
       "      <td>0.965022</td>\n",
       "      <td>0.014574</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.005579</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.004087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.009494</td>\n",
       "      <td>-0.178356</td>\n",
       "      <td>-0.265428</td>\n",
       "      <td>-0.942037</td>\n",
       "      <td>-0.746609</td>\n",
       "      <td>-0.627176</td>\n",
       "      <td>0.113138</td>\n",
       "      <td>0.761583</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.334645</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.614686</td>\n",
       "      <td>0.422626</td>\n",
       "      <td>1.292093</td>\n",
       "      <td>-0.919877</td>\n",
       "      <td>0.515753</td>\n",
       "      <td>-0.078257</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.006459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.142869</td>\n",
       "      <td>-0.219999</td>\n",
       "      <td>-0.998856</td>\n",
       "      <td>0.422626</td>\n",
       "      <td>0.499264</td>\n",
       "      <td>-0.919877</td>\n",
       "      <td>2.011182</td>\n",
       "      <td>1.377634</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.007203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.056229</td>\n",
       "      <td>-0.275847</td>\n",
       "      <td>-1.145542</td>\n",
       "      <td>-1.396925</td>\n",
       "      <td>0.612525</td>\n",
       "      <td>1.129027</td>\n",
       "      <td>0.515753</td>\n",
       "      <td>-0.472976</td>\n",
       "      <td>0.013835</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.005699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num__amt  num__city_pop  num__transaction_hour  \\\n",
       "0 -0.405589      -0.287532              -1.438913   \n",
       "1 -0.009494      -0.178356              -0.265428   \n",
       "2  0.334645       0.027128               0.614686   \n",
       "3  0.142869      -0.219999              -0.998856   \n",
       "4 -0.056229      -0.275847              -1.145542   \n",
       "\n",
       "   num__transaction_day_of_week  num__transaction_day_of_month  \\\n",
       "0                     -0.487149                       1.518615   \n",
       "1                     -0.942037                      -0.746609   \n",
       "2                      0.422626                       1.292093   \n",
       "3                      0.422626                       0.499264   \n",
       "4                     -1.396925                       0.612525   \n",
       "\n",
       "   num__transaction_month  num__age  num__distance  cat__category  \\\n",
       "0               -0.627176  1.148435       0.965022       0.014574   \n",
       "1               -0.627176  0.113138       0.761583       0.004781   \n",
       "2               -0.919877  0.515753      -0.078257       0.001706   \n",
       "3               -0.919877  2.011182       1.377634       0.004781   \n",
       "4                1.129027  0.515753      -0.472976       0.013835   \n",
       "\n",
       "   cat__gender  cat__city  cat__state  cat__zip  cat__job  \n",
       "0     0.005233   0.004400    0.005579  0.004400  0.004087  \n",
       "1     0.005233   0.000419    0.005742  0.000419  0.000419  \n",
       "2     0.006459   0.000000    0.005371  0.000000  0.013575  \n",
       "3     0.005233   0.005700    0.007049  0.005700  0.007203  \n",
       "4     0.005233   0.012225    0.002283  0.012225  0.005699  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651fbde2-6e38-49db-ae05-130711257818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_fraud\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae6f0d9-2f47-45e5-a4ba-0fb16cfde318",
   "metadata": {},
   "source": [
    "# 4. Implement baseline models on **Full Feature Set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70decf9-bed0-4239-903f-4b2e1562b8d8",
   "metadata": {},
   "source": [
    "Note:\n",
    "- Challenge: Memory Error because our dataset is too big.\n",
    "- Use pandas DataFrame  ---> Support Vector ---> Memory Error  ---> Switch using Sparse Matrix.\n",
    "- 10 hours ---> run to Naive Bays but got error. Naive Bays: TypeError: Sparse data was passed for X, but dense data is required. Use '.toarray()' to convert to a dense numpy array.\n",
    "- ----> Try Downsampling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce1eb691-5ea6-4d17-8124-112dc7f84e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Downsampling\n",
    "X_train_small = X_train.sample(frac=0.1, random_state=42)\n",
    "y_train_small = y_train.loc[X_train_small.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d514a96d-a0a8-41e6-9bfd-1d487a3adb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((206267, 14), (206267, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape\n",
    "X_train_small.shape, y_train_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18bb6682-b6cd-4a2f-8909-1fb81ff4f7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num__amt', 'num__city_pop', 'num__transaction_hour',\n",
       "       'num__transaction_day_of_week', 'num__transaction_day_of_month',\n",
       "       'num__transaction_month', 'num__age', 'num__distance', 'cat__category',\n",
       "       'cat__gender', 'cat__city', 'cat__state', 'cat__zip', 'cat__job'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b4dcbc6-8204-47d8-b7ed-862bcfb2694b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fraud\n",
       "1           103222\n",
       "0           103045\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check distribution of target variable\n",
    "y_train_small.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db6e5f6a-0833-45bd-a692-40d99d083864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Logistic Regression===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.8708760974852982\n",
      "  Precision: 0.9368768110981814\n",
      "  Recall: 0.7955765243843367\n",
      "  F1 Score: 0.8604643852553491\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9439913625233771\n",
      "  Precision: 0.07626236335242062\n",
      "  Recall: 0.7808127914723517\n",
      "  F1 Score: 0.13895310925366056\n",
      "\n",
      "Confusion Matrix:\n",
      "[[243638  14196]\n",
      " [   329   1172]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97    257834\n",
      "           1       0.08      0.78      0.14      1501\n",
      "\n",
      "    accuracy                           0.94    259335\n",
      "   macro avg       0.54      0.86      0.56    259335\n",
      "weighted avg       0.99      0.94      0.97    259335\n",
      "\n",
      "\n",
      "==========Support Vector Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9199629606286996\n",
      "  Precision: 0.9333959755695279\n",
      "  Recall: 0.9046133576175621\n",
      "  F1 Score: 0.9187793034571314\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9342009370119729\n",
      "  Precision: 0.07152689829855184\n",
      "  Recall: 0.8654230512991339\n",
      "  F1 Score: 0.1321330485199878\n",
      "\n",
      "Confusion Matrix:\n",
      "[[240972  16862]\n",
      " [   202   1299]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97    257834\n",
      "           1       0.07      0.87      0.13      1501\n",
      "\n",
      "    accuracy                           0.93    259335\n",
      "   macro avg       0.54      0.90      0.55    259335\n",
      "weighted avg       0.99      0.93      0.96    259335\n",
      "\n",
      "\n",
      "==========Gaussian Naive Bayes===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.774418593376546\n",
      "  Precision: 0.94542568905371\n",
      "  Recall: 0.5828699308286993\n",
      "  F1 Score: 0.721143473570658\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9638228546089035\n",
      "  Precision: 0.08569025339081064\n",
      "  Recall: 0.5429713524317122\n",
      "  F1 Score: 0.1480203414456956\n",
      "\n",
      "Confusion Matrix:\n",
      "[[249138   8696]\n",
      " [   686    815]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    257834\n",
      "           1       0.09      0.54      0.15      1501\n",
      "\n",
      "    accuracy                           0.96    259335\n",
      "   macro avg       0.54      0.75      0.56    259335\n",
      "weighted avg       0.99      0.96      0.98    259335\n",
      "\n",
      "\n",
      "==========Random Forest Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 1.0\n",
      "  Precision: 1.0\n",
      "  Recall: 1.0\n",
      "  F1 Score: 1.0\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9961285595850926\n",
      "  Precision: 0.6201063315611407\n",
      "  Recall: 0.854763491005996\n",
      "  F1 Score: 0.7187675070028011\n",
      "\n",
      "Confusion Matrix:\n",
      "[[257048    786]\n",
      " [   218   1283]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.62      0.85      0.72      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.81      0.93      0.86    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "\n",
      "==========K-Nearest Neighbors Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9743924137162028\n",
      "  Precision: 0.952061370308144\n",
      "  Recall: 0.9991377807056635\n",
      "  F1 Score: 0.9750316712991851\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.928258815817379\n",
      "  Precision: 0.0637179879604122\n",
      "  Recall: 0.832111925383078\n",
      "  F1 Score: 0.11837179547931574\n",
      "\n",
      "Confusion Matrix:\n",
      "[[239481  18353]\n",
      " [   252   1249]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    257834\n",
      "           1       0.06      0.83      0.12      1501\n",
      "\n",
      "    accuracy                           0.93    259335\n",
      "   macro avg       0.53      0.88      0.54    259335\n",
      "weighted avg       0.99      0.93      0.96    259335\n",
      "\n",
      "\n",
      "==========AdaBoost Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.96775538501069\n",
      "  Precision: 0.9707336095539849\n",
      "  Recall: 0.9646490089322044\n",
      "  F1 Score: 0.967681744631846\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9701929936182929\n",
      "  Precision: 0.14620015903669203\n",
      "  Recall: 0.8574283810792804\n",
      "  F1 Score: 0.24980590062111802\n",
      "\n",
      "Confusion Matrix:\n",
      "[[250318   7516]\n",
      " [   214   1287]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    257834\n",
      "           1       0.15      0.86      0.25      1501\n",
      "\n",
      "    accuracy                           0.97    259335\n",
      "   macro avg       0.57      0.91      0.62    259335\n",
      "weighted avg       0.99      0.97      0.98    259335\n",
      "\n",
      "\n",
      "==========Gradient Boosting Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.979182321941949\n",
      "  Precision: 0.9835946971178288\n",
      "  Recall: 0.9746565654608513\n",
      "  F1 Score: 0.9791052329372378\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9827905990321399\n",
      "  Precision: 0.2347779369627507\n",
      "  Recall: 0.8734177215189873\n",
      "  F1 Score: 0.37007762879322514\n",
      "\n",
      "Confusion Matrix:\n",
      "[[253561   4273]\n",
      " [   190   1311]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    257834\n",
      "           1       0.23      0.87      0.37      1501\n",
      "\n",
      "    accuracy                           0.98    259335\n",
      "   macro avg       0.62      0.93      0.68    259335\n",
      "weighted avg       0.99      0.98      0.99    259335\n",
      "\n",
      "\n",
      "==========XGBoost===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9995442799866193\n",
      "  Precision: 0.9997577002849445\n",
      "  Recall: 0.9993315378504583\n",
      "  F1 Score: 0.9995445736434109\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9980372876780997\n",
      "  Precision: 0.7987951807228916\n",
      "  Recall: 0.8834110592938041\n",
      "  F1 Score: 0.8389750079088896\n",
      "\n",
      "Confusion Matrix:\n",
      "[[257500    334]\n",
      " [   175   1326]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.80      0.88      0.84      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.90      0.94      0.92    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "\n",
      "==========Bagging Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9996800263735838\n",
      "  Precision: 0.9998933881253755\n",
      "  Recall: 0.9994671678518146\n",
      "  F1 Score: 0.9996802325581395\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9951182833015212\n",
      "  Precision: 0.5484936029715229\n",
      "  Recall: 0.8854097268487675\n",
      "  F1 Score: 0.6773700305810397\n",
      "\n",
      "Confusion Matrix:\n",
      "[[256740   1094]\n",
      " [   172   1329]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.55      0.89      0.68      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.77      0.94      0.84    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "Best model is:  XGBoost\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifiers\n",
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"K-Nearest Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective='multi:softmax', num_class=2),\n",
    "    \"Bagging Classifier\": BaggingClassifier(),\n",
    "}\n",
    "\n",
    "# # Initialize DataFrame to store results\n",
    "# metrics_df = pd.DataFrame(columns=['Classifier', 'Train Accuracy', 'Train Precision', 'Train Recall', 'Train F1', \n",
    "#                                    'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1'])\n",
    "\n",
    "best_precision_score = 0\n",
    "\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n=========={name}===========\")\n",
    "    \n",
    "    clf.fit(X_train_small, y_train_small)         # Train\n",
    "    y_train_pred = clf.predict(X_train_small)     # Predict on training data\n",
    "    y_test_pred = clf.predict(X_test)             # Predict on testing data\n",
    "    \n",
    "   \n",
    "    # Evaluation Metrics for Training Set\n",
    "    train_accuracy = accuracy_score(y_train_small, y_train_pred)\n",
    "    train_precision = precision_score(y_train_small, y_train_pred)\n",
    "    train_recall = recall_score(y_train_small, y_train_pred)\n",
    "    train_f1 = f1_score(y_train_small, y_train_pred)\n",
    "    \n",
    "    print(\"\\nTraining Metrics:\")\n",
    "    print(f\"  Accuracy: {train_accuracy}\")\n",
    "    print(f\"  Precision: {train_precision}\")\n",
    "    print(f\"  Recall: {train_recall}\")\n",
    "    print(f\"  F1 Score: {train_f1}\")\n",
    "    \n",
    "    # Evaluation Metrics for Testing Set\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(\"\\nTesting Metrics:\")\n",
    "    print(f\"  Accuracy: {test_accuracy}\")\n",
    "    print(f\"  Precision: {test_precision}\")\n",
    "    print(f\"  Recall: {test_recall}\")\n",
    "    print(f\"  F1 Score: {test_f1}\")\n",
    "    \n",
    "    # Confusion Matrix for Testing Set\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    \n",
    "    # Classification Report for Testing Set\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    if test_precision > best_precision_score:\n",
    "        best_precision_score = test_precision\n",
    "        best_model_name = name\n",
    "print(\"Best model is: \", best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "097ec4d4-cc8c-4739-af34-0f107ede3ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is:  XGBoost \n",
      " with Precision Score 0.7987951807228916\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model is: \", best_model_name, \"\\n with Precision Score\", best_precision_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd18d0d-fddb-41b7-9e03-38b5ba239316",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "\n",
    "- The best performing baseline models are **XGBoost** (with Precision Score 0.7988), **Random Forest** (with Precision Score 0.62)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c17840-993d-4329-b9f8-797994e8ad53",
   "metadata": {},
   "source": [
    "# _______________________________________________________\n",
    "# 5. Re-train baseline models on **Small Feature Subset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e70e9a-c80b-4afb-acf3-681acdc122a6",
   "metadata": {},
   "source": [
    "## 5.1. Try subset of 13 features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a182bb3-cde5-49f6-bb1a-007374c198bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try subset of 13 features (exclude 'city')\n",
    "\n",
    "features = ['num__amt', 'num__city_pop', 'num__transaction_hour',\n",
    "       'num__transaction_day_of_week', 'num__transaction_day_of_month',\n",
    "       'num__transaction_month', 'num__age', 'num__distance', 'cat__category',\n",
    "       'cat__gender', 'cat__state', 'cat__zip', 'cat__job']\n",
    "X_train_small_subset = X_train_small[features]\n",
    "X_test_subset = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9151790e-19b7-4508-a1c0-4be817aeec16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Logistic Regression===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.8708130723770646\n",
      "  Precision: 0.9438152754755474\n",
      "  Recall: 0.7888047121737614\n",
      "  F1 Score: 0.8593759070351626\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9509437600015425\n",
      "  Precision: 0.0863378308633783\n",
      "  Recall: 0.7801465689540307\n",
      "  F1 Score: 0.15546999468932554\n",
      "\n",
      "Confusion Matrix:\n",
      "[[245442  12392]\n",
      " [   330   1171]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97    257834\n",
      "           1       0.09      0.78      0.16      1501\n",
      "\n",
      "    accuracy                           0.95    259335\n",
      "   macro avg       0.54      0.87      0.57    259335\n",
      "weighted avg       0.99      0.95      0.97    259335\n",
      "\n",
      "\n",
      "==========Support Vector Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9187073065492783\n",
      "  Precision: 0.9316742894805169\n",
      "  Recall: 0.9038383290383832\n",
      "  F1 Score: 0.9175452399685288\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9324965777854898\n",
      "  Precision: 0.06991992260977052\n",
      "  Recall: 0.8667554963357762\n",
      "  F1 Score: 0.1294012333399642\n",
      "\n",
      "Confusion Matrix:\n",
      "[[240528  17306]\n",
      " [   200   1301]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    257834\n",
      "           1       0.07      0.87      0.13      1501\n",
      "\n",
      "    accuracy                           0.93    259335\n",
      "   macro avg       0.53      0.90      0.55    259335\n",
      "weighted avg       0.99      0.93      0.96    259335\n",
      "\n",
      "\n",
      "==========Gaussian Naive Bayes===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.7806338386654191\n",
      "  Precision: 0.9556271612700409\n",
      "  Recall: 0.5889926566042123\n",
      "  F1 Score: 0.728797305234893\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.970223841749089\n",
      "  Precision: 0.10551680405833862\n",
      "  Recall: 0.5542971352431713\n",
      "  F1 Score: 0.1772853185595568\n",
      "\n",
      "Confusion Matrix:\n",
      "[[250781   7053]\n",
      " [   669    832]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    257834\n",
      "           1       0.11      0.55      0.18      1501\n",
      "\n",
      "    accuracy                           0.97    259335\n",
      "   macro avg       0.55      0.76      0.58    259335\n",
      "weighted avg       0.99      0.97      0.98    259335\n",
      "\n",
      "\n",
      "==========Random Forest Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 1.0\n",
      "  Precision: 1.0\n",
      "  Recall: 1.0\n",
      "  F1 Score: 1.0\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9966259856941794\n",
      "  Precision: 0.6596938775510204\n",
      "  Recall: 0.8614257161892072\n",
      "  F1 Score: 0.7471828951170182\n",
      "\n",
      "Confusion Matrix:\n",
      "[[257167    667]\n",
      " [   208   1293]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.66      0.86      0.75      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.83      0.93      0.87    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "\n",
      "==========K-Nearest Neighbors Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9741354651980201\n",
      "  Precision: 0.9515957888520838\n",
      "  Recall: 0.9991377807056635\n",
      "  F1 Score: 0.9747874537454927\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.927599437021613\n",
      "  Precision: 0.06307855733724518\n",
      "  Recall: 0.8307794803464357\n",
      "  F1 Score: 0.11725434884814293\n",
      "\n",
      "Confusion Matrix:\n",
      "[[239312  18522]\n",
      " [   254   1247]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    257834\n",
      "           1       0.06      0.83      0.12      1501\n",
      "\n",
      "    accuracy                           0.93    259335\n",
      "   macro avg       0.53      0.88      0.54    259335\n",
      "weighted avg       0.99      0.93      0.96    259335\n",
      "\n",
      "\n",
      "==========AdaBoost Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.96775538501069\n",
      "  Precision: 0.9707336095539849\n",
      "  Recall: 0.9646490089322044\n",
      "  F1 Score: 0.967681744631846\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9701929936182929\n",
      "  Precision: 0.14620015903669203\n",
      "  Recall: 0.8574283810792804\n",
      "  F1 Score: 0.24980590062111802\n",
      "\n",
      "Confusion Matrix:\n",
      "[[250318   7516]\n",
      " [   214   1287]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    257834\n",
      "           1       0.15      0.86      0.25      1501\n",
      "\n",
      "    accuracy                           0.97    259335\n",
      "   macro avg       0.57      0.91      0.62    259335\n",
      "weighted avg       0.99      0.97      0.98    259335\n",
      "\n",
      "\n",
      "==========Gradient Boosting Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9791774738567003\n",
      "  Precision: 0.9831505123221036\n",
      "  Recall: 0.9751022068938792\n",
      "  F1 Score: 0.9791098205730573\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9824859737405287\n",
      "  Precision: 0.23178691127182924\n",
      "  Recall: 0.8754163890739507\n",
      "  F1 Score: 0.36652719665271966\n",
      "\n",
      "Confusion Matrix:\n",
      "[[253479   4355]\n",
      " [   187   1314]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    257834\n",
      "           1       0.23      0.88      0.37      1501\n",
      "\n",
      "    accuracy                           0.98    259335\n",
      "   macro avg       0.62      0.93      0.68    259335\n",
      "weighted avg       0.99      0.98      0.99    259335\n",
      "\n",
      "\n",
      "==========XGBoost===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.999549128071868\n",
      "  Precision: 0.9998255222216837\n",
      "  Recall: 0.9992734107070198\n",
      "  F1 Score: 0.9995493902232214\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9980449997107987\n",
      "  Precision: 0.8026796589524969\n",
      "  Recall: 0.8780812791472352\n",
      "  F1 Score: 0.8386891504931594\n",
      "\n",
      "Confusion Matrix:\n",
      "[[257510    324]\n",
      " [   183   1318]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.80      0.88      0.84      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.90      0.94      0.92    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "\n",
      "==========Bagging Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9996363936063452\n",
      "  Precision: 0.9998836882457279\n",
      "  Recall: 0.9993896649938967\n",
      "  F1 Score: 0.9996366155828929\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9951028592361232\n",
      "  Precision: 0.547945205479452\n",
      "  Recall: 0.8794137241838774\n",
      "  F1 Score: 0.6751918158567775\n",
      "\n",
      "Confusion Matrix:\n",
      "[[256745   1089]\n",
      " [   181   1320]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.55      0.88      0.68      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.77      0.94      0.84    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "==========\n",
      "Best model is:  XGBoost\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifiers\n",
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"K-Nearest Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective='multi:softmax', num_class=2),\n",
    "    \"Bagging Classifier\": BaggingClassifier(),\n",
    "}\n",
    "\n",
    "# # Initialize DataFrame to store results\n",
    "# metrics_df = pd.DataFrame(columns=['Classifier', 'Train Accuracy', 'Train Precision', 'Train Recall', 'Train F1', \n",
    "#                                    'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1'])\n",
    "\n",
    "best_precision_score = 0\n",
    "\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n=========={name}===========\")\n",
    "    \n",
    "    clf.fit(X_train_small_subset, y_train_small)         # Train\n",
    "    y_train_pred = clf.predict(X_train_small_subset)     # Predict on training data\n",
    "    y_test_pred = clf.predict(X_test_subset)             # Predict on testing data\n",
    "    \n",
    "   \n",
    "    # Evaluation Metrics for Training Set\n",
    "    train_accuracy = accuracy_score(y_train_small, y_train_pred)\n",
    "    train_precision = precision_score(y_train_small, y_train_pred)\n",
    "    train_recall = recall_score(y_train_small, y_train_pred)\n",
    "    train_f1 = f1_score(y_train_small, y_train_pred)\n",
    "    \n",
    "    print(\"\\nTraining Metrics:\")\n",
    "    print(f\"  Accuracy: {train_accuracy}\")\n",
    "    print(f\"  Precision: {train_precision}\")\n",
    "    print(f\"  Recall: {train_recall}\")\n",
    "    print(f\"  F1 Score: {train_f1}\")\n",
    "    \n",
    "    # Evaluation Metrics for Testing Set\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(\"\\nTesting Metrics:\")\n",
    "    print(f\"  Accuracy: {test_accuracy}\")\n",
    "    print(f\"  Precision: {test_precision}\")\n",
    "    print(f\"  Recall: {test_recall}\")\n",
    "    print(f\"  F1 Score: {test_f1}\")\n",
    "    \n",
    "    # Confusion Matrix for Testing Set\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    \n",
    "    # Classification Report for Testing Set\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    if test_precision > best_precision_score:\n",
    "        best_precision_score = test_precision\n",
    "        best_model_name = name\n",
    "\n",
    "print(\"=\"*10)\n",
    "print(\"Best model is: \", best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81275b9b-26f6-4887-a95d-7eaa9097f5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is:  XGBoost \n",
      " with Precision Score 0.8026796589524969\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model is: \", best_model_name, \"\\n with Precision Score\", best_precision_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc06daed-adcb-49ea-9446-677fab6462e5",
   "metadata": {},
   "source": [
    "### Comment:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e783f3a-2625-4996-bd67-9cb95ff238f9",
   "metadata": {},
   "source": [
    "- The best performing baseline models are **XGBoost** (with Precision Score 0.8026), **Random Forest** (with Precision Score 0.66).\n",
    "- ==> the result got a little better but not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe70e6-a65b-40e6-a169-b26a62040a94",
   "metadata": {},
   "source": [
    "## 5.2. Try subset of 12 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a77a245d-dd56-4ef2-8568-610dc6ba9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try subset of 13 features (exclude 'city' and 'state')\n",
    "\n",
    "features = ['num__amt', 'num__city_pop', 'num__transaction_hour',\n",
    "       'num__transaction_day_of_week', 'num__transaction_day_of_month',\n",
    "       'num__transaction_month', 'num__age', 'num__distance', 'cat__category',\n",
    "       'cat__gender', 'cat__zip', 'cat__job']\n",
    "X_train_small_subset = X_train_small[features]\n",
    "X_test_subset = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eefbb93e-7fef-4d61-9340-03bcfc54c62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Logistic Regression===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.8708033762065672\n",
      "  Precision: 0.9438139728980954\n",
      "  Recall: 0.788785336459282\n",
      "  F1 Score: 0.8593638680873296\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9509746081323385\n",
      "  Precision: 0.08638878642567319\n",
      "  Recall: 0.7801465689540307\n",
      "  F1 Score: 0.15555260361317746\n",
      "\n",
      "Confusion Matrix:\n",
      "[[245450  12384]\n",
      " [   330   1171]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97    257834\n",
      "           1       0.09      0.78      0.16      1501\n",
      "\n",
      "    accuracy                           0.95    259335\n",
      "   macro avg       0.54      0.87      0.57    259335\n",
      "weighted avg       0.99      0.95      0.97    259335\n",
      "\n",
      "\n",
      "==========Support Vector Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.918750939316517\n",
      "  Precision: 0.9316890508762294\n",
      "  Recall: 0.9039158318963012\n",
      "  F1 Score: 0.9175923330727207\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9324927217691403\n",
      "  Precision: 0.06991616509028376\n",
      "  Recall: 0.8667554963357762\n",
      "  F1 Score: 0.12939479834899797\n",
      "\n",
      "Confusion Matrix:\n",
      "[[240527  17307]\n",
      " [   200   1301]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    257834\n",
      "           1       0.07      0.87      0.13      1501\n",
      "\n",
      "    accuracy                           0.93    259335\n",
      "   macro avg       0.53      0.90      0.55    259335\n",
      "weighted avg       0.99      0.93      0.96    259335\n",
      "\n",
      "\n",
      "==========Gaussian Naive Bayes===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.7866115277771044\n",
      "  Precision: 0.9513347867847723\n",
      "  Recall: 0.6045126039022689\n",
      "  F1 Score: 0.7392677104251449\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9658202710779493\n",
      "  Precision: 0.0950390496095039\n",
      "  Recall: 0.5756162558294471\n",
      "  F1 Score: 0.16314199395770393\n",
      "\n",
      "Confusion Matrix:\n",
      "[[249607   8227]\n",
      " [   637    864]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    257834\n",
      "           1       0.10      0.58      0.16      1501\n",
      "\n",
      "    accuracy                           0.97    259335\n",
      "   macro avg       0.55      0.77      0.57    259335\n",
      "weighted avg       0.99      0.97      0.98    259335\n",
      "\n",
      "\n",
      "==========Random Forest Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 1.0\n",
      "  Precision: 1.0\n",
      "  Recall: 1.0\n",
      "  F1 Score: 1.0\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9965912815470338\n",
      "  Precision: 0.6552591847005536\n",
      "  Recall: 0.8674217188540972\n",
      "  F1 Score: 0.7465596330275229\n",
      "\n",
      "Confusion Matrix:\n",
      "[[257149    685]\n",
      " [   199   1302]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.66      0.87      0.75      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.83      0.93      0.87    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "\n",
      "==========K-Nearest Neighbors Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9741354651980201\n",
      "  Precision: 0.9515957888520838\n",
      "  Recall: 0.9991377807056635\n",
      "  F1 Score: 0.9747874537454927\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.927591724988914\n",
      "  Precision: 0.0630721764200091\n",
      "  Recall: 0.8307794803464357\n",
      "  F1 Score: 0.11724332455810454\n",
      "\n",
      "Confusion Matrix:\n",
      "[[239310  18524]\n",
      " [   254   1247]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    257834\n",
      "           1       0.06      0.83      0.12      1501\n",
      "\n",
      "    accuracy                           0.93    259335\n",
      "   macro avg       0.53      0.88      0.54    259335\n",
      "weighted avg       0.99      0.93      0.96    259335\n",
      "\n",
      "\n",
      "==========AdaBoost Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.967503284577756\n",
      "  Precision: 0.9710679668511523\n",
      "  Recall: 0.9637771017806281\n",
      "  F1 Score: 0.9674087976311452\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9715464553569707\n",
      "  Precision: 0.15276465028355388\n",
      "  Recall: 0.8614257161892072\n",
      "  F1 Score: 0.2595082789764175\n",
      "\n",
      "Confusion Matrix:\n",
      "[[250663   7171]\n",
      " [   208   1293]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99    257834\n",
      "           1       0.15      0.86      0.26      1501\n",
      "\n",
      "    accuracy                           0.97    259335\n",
      "   macro avg       0.58      0.92      0.62    259335\n",
      "weighted avg       0.99      0.97      0.98    259335\n",
      "\n",
      "\n",
      "==========Gradient Boosting Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9807240130510455\n",
      "  Precision: 0.9841268292682926\n",
      "  Recall: 0.9772432233438608\n",
      "  F1 Score: 0.9806729469867103\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9833805695336149\n",
      "  Precision: 0.2426241524647242\n",
      "  Recall: 0.8820786142571619\n",
      "  F1 Score: 0.38056912906007473\n",
      "\n",
      "Confusion Matrix:\n",
      "[[253701   4133]\n",
      " [   177   1324]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    257834\n",
      "           1       0.24      0.88      0.38      1501\n",
      "\n",
      "    accuracy                           0.98    259335\n",
      "   macro avg       0.62      0.93      0.69    259335\n",
      "weighted avg       0.99      0.98      0.99    259335\n",
      "\n",
      "\n",
      "==========XGBoost===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9995103433898782\n",
      "  Precision: 0.9997770604941503\n",
      "  Recall: 0.9992443471353006\n",
      "  F1 Score: 0.9995106328341142\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9979794474328572\n",
      "  Precision: 0.7885410513880685\n",
      "  Recall: 0.8894070619586942\n",
      "  F1 Score: 0.8359423919849718\n",
      "\n",
      "Confusion Matrix:\n",
      "[[257476    358]\n",
      " [   166   1335]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.79      0.89      0.84      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.89      0.94      0.92    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "\n",
      "==========Bagging Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9996751782883351\n",
      "  Precision: 0.9998449417077733\n",
      "  Recall: 0.9995059192807735\n",
      "  F1 Score: 0.9996754017508926\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9954113405440839\n",
      "  Precision: 0.5660297239915074\n",
      "  Recall: 0.8880746169220519\n",
      "  F1 Score: 0.6913900414937759\n",
      "\n",
      "Confusion Matrix:\n",
      "[[256812   1022]\n",
      " [   168   1333]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.57      0.89      0.69      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.78      0.94      0.84    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "==========\n",
      "Best model is:  XGBoost\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifiers\n",
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"K-Nearest Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective='multi:softmax', num_class=2),\n",
    "    \"Bagging Classifier\": BaggingClassifier(),\n",
    "}\n",
    "\n",
    "# # Initialize DataFrame to store results\n",
    "# metrics_df = pd.DataFrame(columns=['Classifier', 'Train Accuracy', 'Train Precision', 'Train Recall', 'Train F1', \n",
    "#                                    'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1'])\n",
    "\n",
    "best_precision_score = 0\n",
    "\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n=========={name}===========\")\n",
    "    \n",
    "    clf.fit(X_train_small_subset, y_train_small)         # Train\n",
    "    y_train_pred = clf.predict(X_train_small_subset)     # Predict on training data\n",
    "    y_test_pred = clf.predict(X_test_subset)             # Predict on testing data\n",
    "    \n",
    "   \n",
    "    # Evaluation Metrics for Training Set\n",
    "    train_accuracy = accuracy_score(y_train_small, y_train_pred)\n",
    "    train_precision = precision_score(y_train_small, y_train_pred)\n",
    "    train_recall = recall_score(y_train_small, y_train_pred)\n",
    "    train_f1 = f1_score(y_train_small, y_train_pred)\n",
    "    \n",
    "    print(\"\\nTraining Metrics:\")\n",
    "    print(f\"  Accuracy: {train_accuracy}\")\n",
    "    print(f\"  Precision: {train_precision}\")\n",
    "    print(f\"  Recall: {train_recall}\")\n",
    "    print(f\"  F1 Score: {train_f1}\")\n",
    "    \n",
    "    # Evaluation Metrics for Testing Set\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(\"\\nTesting Metrics:\")\n",
    "    print(f\"  Accuracy: {test_accuracy}\")\n",
    "    print(f\"  Precision: {test_precision}\")\n",
    "    print(f\"  Recall: {test_recall}\")\n",
    "    print(f\"  F1 Score: {test_f1}\")\n",
    "    \n",
    "    # Confusion Matrix for Testing Set\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    \n",
    "    # Classification Report for Testing Set\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    if test_precision > best_precision_score:\n",
    "        best_precision_score = test_precision\n",
    "        best_model_name = name\n",
    "\n",
    "print(\"=\"*10)\n",
    "print(\"Best model is: \", best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "624d962c-aa0c-48d5-9f4e-7c69a45f365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is:  XGBoost \n",
      " with Precision Score 0.7885410513880685\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model is: \", best_model_name, \"\\n with Precision Score\", best_precision_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbbc2aa-568f-4e5e-bbc1-cec2219fc689",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "- The best performing baseline models are **XGBoost** (with Precision Score 0.7885), **Random Forest** (with Precision Score 0.66).\n",
    "- ==> the result did not get better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e757733e-f8a3-49c2-8369-42bd58e0589b",
   "metadata": {},
   "source": [
    "## 5.3. Try subset of 7 features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "475457ff-f8e5-48b0-995c-9fa3acf15a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try subset of 7 features: amount, hour, category, gender, job, state, zip\n",
    "\n",
    "features = ['num__amt', 'num__transaction_hour', 'cat__category', 'cat__gender', 'cat__job', 'cat__state', 'cat__zip']\n",
    "X_train_small_subset = X_train_small[features]\n",
    "X_test_subset = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2da6eec1-f299-4eb6-a022-b00050cb4b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Logistic Regression===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.8723305230599175\n",
      "  Precision: 0.9453248077101288\n",
      "  Recall: 0.7906066536203522\n",
      "  F1 Score: 0.8610709575309945\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9523512059691133\n",
      "  Precision: 0.08885017421602788\n",
      "  Recall: 0.7814790139906729\n",
      "  F1 Score: 0.15955927361762906\n",
      "\n",
      "Confusion Matrix:\n",
      "[[245805  12029]\n",
      " [   328   1173]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98    257834\n",
      "           1       0.09      0.78      0.16      1501\n",
      "\n",
      "    accuracy                           0.95    259335\n",
      "   macro avg       0.54      0.87      0.57    259335\n",
      "weighted avg       0.99      0.95      0.97    259335\n",
      "\n",
      "\n",
      "==========Support Vector Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9031304086451056\n",
      "  Precision: 0.9402655101285238\n",
      "  Recall: 0.8611342543256283\n",
      "  F1 Score: 0.8989618572288213\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9445620529431045\n",
      "  Precision: 0.08259854771784232\n",
      "  Recall: 0.8487674883411059\n",
      "  F1 Score: 0.15054652880354505\n",
      "\n",
      "Confusion Matrix:\n",
      "[[243684  14150]\n",
      " [   227   1274]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97    257834\n",
      "           1       0.08      0.85      0.15      1501\n",
      "\n",
      "    accuracy                           0.94    259335\n",
      "   macro avg       0.54      0.90      0.56    259335\n",
      "weighted avg       0.99      0.94      0.97    259335\n",
      "\n",
      "\n",
      "==========Gaussian Naive Bayes===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.7801053973733074\n",
      "  Precision: 0.9554792903134397\n",
      "  Recall: 0.5879851194512797\n",
      "  F1 Score: 0.7279825839765387\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9702585458962346\n",
      "  Precision: 0.10583756345177665\n",
      "  Recall: 0.5556295802798135\n",
      "  F1 Score: 0.17780620402942118\n",
      "\n",
      "Confusion Matrix:\n",
      "[[250788   7046]\n",
      " [   667    834]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    257834\n",
      "           1       0.11      0.56      0.18      1501\n",
      "\n",
      "    accuracy                           0.97    259335\n",
      "   macro avg       0.55      0.76      0.58    259335\n",
      "weighted avg       0.99      0.97      0.98    259335\n",
      "\n",
      "\n",
      "==========Random Forest Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 1.0\n",
      "  Precision: 1.0\n",
      "  Recall: 1.0\n",
      "  F1 Score: 1.0\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9953727803805889\n",
      "  Precision: 0.5652362375379281\n",
      "  Recall: 0.8687541638907396\n",
      "  F1 Score: 0.6848739495798319\n",
      "\n",
      "Confusion Matrix:\n",
      "[[256831   1003]\n",
      " [   197   1304]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.57      0.87      0.68      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.78      0.93      0.84    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "\n",
      "==========K-Nearest Neighbors Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9779557563740201\n",
      "  Precision: 0.9766033288575044\n",
      "  Recall: 0.9794133033655616\n",
      "  F1 Score: 0.9780062977348469\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.969618447182216\n",
      "  Precision: 0.148478835978836\n",
      "  Recall: 0.8974017321785477\n",
      "  F1 Score: 0.2547999621677859\n",
      "\n",
      "Confusion Matrix:\n",
      "[[250109   7725]\n",
      " [   154   1347]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    257834\n",
      "           1       0.15      0.90      0.25      1501\n",
      "\n",
      "    accuracy                           0.97    259335\n",
      "   macro avg       0.57      0.93      0.62    259335\n",
      "weighted avg       0.99      0.97      0.98    259335\n",
      "\n",
      "\n",
      "==========AdaBoost Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9676778156467103\n",
      "  Precision: 0.9701239641253858\n",
      "  Recall: 0.9651334017941912\n",
      "  F1 Score: 0.967622248231049\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9705284670407003\n",
      "  Precision: 0.148868053967528\n",
      "  Recall: 0.8674217188540972\n",
      "  F1 Score: 0.25412315799746266\n",
      "\n",
      "Confusion Matrix:\n",
      "[[250390   7444]\n",
      " [   199   1302]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    257834\n",
      "           1       0.15      0.87      0.25      1501\n",
      "\n",
      "    accuracy                           0.97    259335\n",
      "   macro avg       0.57      0.92      0.62    259335\n",
      "weighted avg       0.99      0.97      0.98    259335\n",
      "\n",
      "\n",
      "==========Gradient Boosting Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.981111859870944\n",
      "  Precision: 0.9843564086059259\n",
      "  Recall: 0.9777954312065258\n",
      "  F1 Score: 0.9810649507183266\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9834461218115564\n",
      "  Precision: 0.24366507528461256\n",
      "  Recall: 0.8840772818121253\n",
      "  F1 Score: 0.3820354109687635\n",
      "\n",
      "Confusion Matrix:\n",
      "[[253715   4119]\n",
      " [   174   1327]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    257834\n",
      "           1       0.24      0.88      0.38      1501\n",
      "\n",
      "    accuracy                           0.98    259335\n",
      "   macro avg       0.62      0.93      0.69    259335\n",
      "weighted avg       0.99      0.98      0.99    259335\n",
      "\n",
      "\n",
      "==========XGBoost===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9979928927070254\n",
      "  Precision: 0.9986032435788004\n",
      "  Recall: 0.9973842785452713\n",
      "  F1 Score: 0.997993388846344\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9962442400755779\n",
      "  Precision: 0.6287249633610161\n",
      "  Recall: 0.8574283810792804\n",
      "  F1 Score: 0.7254791431792559\n",
      "\n",
      "Confusion Matrix:\n",
      "[[257074    760]\n",
      " [   214   1287]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.63      0.86      0.73      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.81      0.93      0.86    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "\n",
      "==========Bagging Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9995006472193807\n",
      "  Precision: 0.9998061245262169\n",
      "  Recall: 0.999195907849102\n",
      "  F1 Score: 0.999500923050087\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9946517053232306\n",
      "  Precision: 0.5227272727272727\n",
      "  Recall: 0.8734177215189873\n",
      "  F1 Score: 0.6540284360189573\n",
      "\n",
      "Confusion Matrix:\n",
      "[[256637   1197]\n",
      " [   190   1311]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.52      0.87      0.65      1501\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.76      0.93      0.83    259335\n",
      "weighted avg       1.00      0.99      1.00    259335\n",
      "\n",
      "==========\n",
      "Best model is:  XGBoost\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifiers\n",
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"K-Nearest Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective='multi:softmax', num_class=2),\n",
    "    \"Bagging Classifier\": BaggingClassifier(),\n",
    "}\n",
    "\n",
    "# # Initialize DataFrame to store results\n",
    "# metrics_df = pd.DataFrame(columns=['Classifier', 'Train Accuracy', 'Train Precision', 'Train Recall', 'Train F1', \n",
    "#                                    'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1'])\n",
    "\n",
    "best_precision_score = 0\n",
    "\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n=========={name}===========\")\n",
    "    \n",
    "    clf.fit(X_train_small_subset, y_train_small)         # Train\n",
    "    y_train_pred = clf.predict(X_train_small_subset)     # Predict on training data\n",
    "    y_test_pred = clf.predict(X_test_subset)             # Predict on testing data\n",
    "    \n",
    "   \n",
    "    # Evaluation Metrics for Training Set\n",
    "    train_accuracy = accuracy_score(y_train_small, y_train_pred)\n",
    "    train_precision = precision_score(y_train_small, y_train_pred)\n",
    "    train_recall = recall_score(y_train_small, y_train_pred)\n",
    "    train_f1 = f1_score(y_train_small, y_train_pred)\n",
    "    \n",
    "    print(\"\\nTraining Metrics:\")\n",
    "    print(f\"  Accuracy: {train_accuracy}\")\n",
    "    print(f\"  Precision: {train_precision}\")\n",
    "    print(f\"  Recall: {train_recall}\")\n",
    "    print(f\"  F1 Score: {train_f1}\")\n",
    "    \n",
    "    # Evaluation Metrics for Testing Set\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(\"\\nTesting Metrics:\")\n",
    "    print(f\"  Accuracy: {test_accuracy}\")\n",
    "    print(f\"  Precision: {test_precision}\")\n",
    "    print(f\"  Recall: {test_recall}\")\n",
    "    print(f\"  F1 Score: {test_f1}\")\n",
    "    \n",
    "    # Confusion Matrix for Testing Set\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    \n",
    "    # Classification Report for Testing Set\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    if test_precision > best_precision_score:\n",
    "        best_precision_score = test_precision\n",
    "        best_model_name = name\n",
    "\n",
    "print(\"=\"*10)\n",
    "print(\"Best model is: \", best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3747b9df-e189-45ae-bdfc-3dea6e47b031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is:  XGBoost \n",
      " with Precision Score 0.6287249633610161\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model is: \", best_model_name, \"\\n with Precision Score\", best_precision_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd98a87-b4a5-4876-af67-4caa3d17afea",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "\n",
    "- The best performing baseline models STILL are **XGBoost** (with Precision Score 0.63), **Random Forest** (with Precision Score 0.57).\n",
    "- ---> the result got worse with small feature subset of 7 features.\n",
    "- ---> NO IMPROVEMENT with small feature subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d19c04-48b8-4675-8f5c-3f9c2abdd30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34b5b27c-707d-4c5d-946e-1530a79cff64",
   "metadata": {},
   "source": [
    "## 5.4. Try subset of 6 features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8ee32c5-3ec2-4ff0-8c66-130fda96da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try subset of 6 features: amount, hour, category, gender, job, zip\n",
    "\n",
    "features = ['num__amt', 'num__transaction_hour', 'cat__category', 'cat__gender', 'cat__job', 'cat__zip']\n",
    "X_train_small_subset = X_train_small[features]\n",
    "X_test_subset = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4a76c38-aa9d-4f4b-9b38-df557e0dc3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Logistic Regression===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.8723450673156636\n",
      "  Precision: 0.94534734208301\n",
      "  Recall: 0.790616341477592\n",
      "  F1 Score: 0.8610860516278113\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9524051901980064\n",
      "  Precision: 0.08894449499545042\n",
      "  Recall: 0.7814790139906729\n",
      "  F1 Score: 0.1597113486282252\n",
      "\n",
      "Confusion Matrix:\n",
      "[[245819  12015]\n",
      " [   328   1173]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98    257834\n",
      "           1       0.09      0.78      0.16      1501\n",
      "\n",
      "    accuracy                           0.95    259335\n",
      "   macro avg       0.54      0.87      0.57    259335\n",
      "weighted avg       0.99      0.95      0.97    259335\n",
      "\n",
      "\n",
      "==========Support Vector Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9032273703500803\n",
      "  Precision: 0.9404924398734512\n",
      "  Recall: 0.861105190753909\n",
      "  F1 Score: 0.8990497190627671\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9449013823818613\n",
      "  Precision: 0.08296373597704149\n",
      "  Recall: 0.8474350433044637\n",
      "  F1 Score: 0.15113170557832828\n",
      "\n",
      "Confusion Matrix:\n",
      "[[243774  14060]\n",
      " [   229   1272]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97    257834\n",
      "           1       0.08      0.85      0.15      1501\n",
      "\n",
      "    accuracy                           0.94    259335\n",
      "   macro avg       0.54      0.90      0.56    259335\n",
      "weighted avg       0.99      0.94      0.97    259335\n",
      "\n",
      "\n",
      "==========Gaussian Naive Bayes===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.7861655039342211\n",
      "  Precision: 0.952080879766293\n",
      "  Recall: 0.6030497374590688\n",
      "  F1 Score: 0.7383973001666637\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.966256000925444\n",
      "  Precision: 0.09596522514489524\n",
      "  Recall: 0.5736175882744837\n",
      "  F1 Score: 0.16442280148954455\n",
      "\n",
      "Confusion Matrix:\n",
      "[[249723   8111]\n",
      " [   640    861]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    257834\n",
      "           1       0.10      0.57      0.16      1501\n",
      "\n",
      "    accuracy                           0.97    259335\n",
      "   macro avg       0.55      0.77      0.57    259335\n",
      "weighted avg       0.99      0.97      0.98    259335\n",
      "\n",
      "\n",
      "==========Random Forest Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 1.0\n",
      "  Precision: 1.0\n",
      "  Recall: 1.0\n",
      "  F1 Score: 1.0\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9953419322497927\n",
      "  Precision: 0.5621552821383115\n",
      "  Recall: 0.882744836775483\n",
      "  F1 Score: 0.6868843960601347\n",
      "\n",
      "Confusion Matrix:\n",
      "[[256802   1032]\n",
      " [   176   1325]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.56      0.88      0.69      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.78      0.94      0.84    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "\n",
      "==========K-Nearest Neighbors Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.978028477652751\n",
      "  Precision: 0.9769844952248385\n",
      "  Recall: 0.9791614190773285\n",
      "  F1 Score: 0.9780717458412767\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9699076484084292\n",
      "  Precision: 0.14979442160240028\n",
      "  Recall: 0.8980679546968687\n",
      "  F1 Score: 0.25676190476190475\n",
      "\n",
      "Confusion Matrix:\n",
      "[[250183   7651]\n",
      " [   153   1348]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    257834\n",
      "           1       0.15      0.90      0.26      1501\n",
      "\n",
      "    accuracy                           0.97    259335\n",
      "   macro avg       0.57      0.93      0.62    259335\n",
      "weighted avg       0.99      0.97      0.98    259335\n",
      "\n",
      "\n",
      "==========AdaBoost Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9669651471151469\n",
      "  Precision: 0.968209103094586\n",
      "  Recall: 0.9656952975140959\n",
      "  F1 Score: 0.9669505665062859\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9687277074054794\n",
      "  Precision: 0.14248620577734503\n",
      "  Recall: 0.8774150566289141\n",
      "  F1 Score: 0.24516008935219658\n",
      "\n",
      "Confusion Matrix:\n",
      "[[249908   7926]\n",
      " [   184   1317]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    257834\n",
      "           1       0.14      0.88      0.25      1501\n",
      "\n",
      "    accuracy                           0.97    259335\n",
      "   macro avg       0.57      0.92      0.61    259335\n",
      "weighted avg       0.99      0.97      0.98    259335\n",
      "\n",
      "\n",
      "==========Gradient Boosting Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.979507143653614\n",
      "  Precision: 0.983284351536336\n",
      "  Recall: 0.9756350390420647\n",
      "  F1 Score: 0.9794447605292719\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9827366148032468\n",
      "  Precision: 0.23532550693703308\n",
      "  Recall: 0.8814123917388408\n",
      "  F1 Score: 0.371472694089569\n",
      "\n",
      "Confusion Matrix:\n",
      "[[253535   4299]\n",
      " [   178   1323]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    257834\n",
      "           1       0.24      0.88      0.37      1501\n",
      "\n",
      "    accuracy                           0.98    259335\n",
      "   macro avg       0.62      0.93      0.68    259335\n",
      "weighted avg       0.99      0.98      0.99    259335\n",
      "\n",
      "\n",
      "==========XGBoost===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9967614790538477\n",
      "  Precision: 0.9976223749078064\n",
      "  Recall: 0.9959020363875918\n",
      "  F1 Score: 0.996761463353146\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.995260955906453\n",
      "  Precision: 0.556525353283458\n",
      "  Recall: 0.8920719520319786\n",
      "  F1 Score: 0.6854363962119273\n",
      "\n",
      "Confusion Matrix:\n",
      "[[256767   1067]\n",
      " [   162   1339]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.56      0.89      0.69      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.78      0.94      0.84    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "\n",
      "==========Bagging Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9995151914751269\n",
      "  Precision: 0.999854583527222\n",
      "  Recall: 0.9991765321346224\n",
      "  F1 Score: 0.9995154428367915\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9947596737810168\n",
      "  Precision: 0.5284911717495987\n",
      "  Recall: 0.8774150566289141\n",
      "  F1 Score: 0.6596543951915853\n",
      "\n",
      "Confusion Matrix:\n",
      "[[256659   1175]\n",
      " [   184   1317]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.53      0.88      0.66      1501\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.76      0.94      0.83    259335\n",
      "weighted avg       1.00      0.99      1.00    259335\n",
      "\n",
      "==========\n",
      "Best model is:  Random Forest Classifier\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifiers\n",
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"K-Nearest Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective='multi:softmax', num_class=2),\n",
    "    \"Bagging Classifier\": BaggingClassifier(),\n",
    "}\n",
    "\n",
    "# # Initialize DataFrame to store results\n",
    "# metrics_df = pd.DataFrame(columns=['Classifier', 'Train Accuracy', 'Train Precision', 'Train Recall', 'Train F1', \n",
    "#                                    'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1'])\n",
    "\n",
    "best_precision_score = 0\n",
    "\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n=========={name}===========\")\n",
    "    \n",
    "    clf.fit(X_train_small_subset, y_train_small)         # Train\n",
    "    y_train_pred = clf.predict(X_train_small_subset)     # Predict on training data\n",
    "    y_test_pred = clf.predict(X_test_subset)             # Predict on testing data\n",
    "    \n",
    "   \n",
    "    # Evaluation Metrics for Training Set\n",
    "    train_accuracy = accuracy_score(y_train_small, y_train_pred)\n",
    "    train_precision = precision_score(y_train_small, y_train_pred)\n",
    "    train_recall = recall_score(y_train_small, y_train_pred)\n",
    "    train_f1 = f1_score(y_train_small, y_train_pred)\n",
    "    \n",
    "    print(\"\\nTraining Metrics:\")\n",
    "    print(f\"  Accuracy: {train_accuracy}\")\n",
    "    print(f\"  Precision: {train_precision}\")\n",
    "    print(f\"  Recall: {train_recall}\")\n",
    "    print(f\"  F1 Score: {train_f1}\")\n",
    "    \n",
    "    # Evaluation Metrics for Testing Set\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(\"\\nTesting Metrics:\")\n",
    "    print(f\"  Accuracy: {test_accuracy}\")\n",
    "    print(f\"  Precision: {test_precision}\")\n",
    "    print(f\"  Recall: {test_recall}\")\n",
    "    print(f\"  F1 Score: {test_f1}\")\n",
    "    \n",
    "    # Confusion Matrix for Testing Set\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    \n",
    "    # Classification Report for Testing Set\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    if test_precision > best_precision_score:\n",
    "        best_precision_score = test_precision\n",
    "        best_model_name = name\n",
    "\n",
    "print(\"=\"*10)\n",
    "print(\"Best model is: \", best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d73ab2f-e7aa-4563-8526-a440ab81171c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is:  Random Forest Classifier \n",
      " with Precision Score 0.5621552821383115\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model is: \", best_model_name, \"\\n with Precision Score\", best_precision_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a7ec5-efc4-4f7f-a0b3-b64e6ffbde71",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "- The best performing baseline models STILL are **XGBoost** (with Precision Score 0.56), **Random Forest** (with Precision Score 0.56).\n",
    "- ---> the result got worse with small feature subset of 6 features.\n",
    "- ---> NO IMPROVEMENT with small feature subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b6bad-4adf-439d-8caf-660091a17729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35688bc0-0d74-4267-a096-028204aa2a26",
   "metadata": {},
   "source": [
    "## 5.5. Try subset of 11 features (just with XGBoost and Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50c86e86-816b-4e70-80de-41a8625b0bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try subset of 11 features (exclude 'state','day of month','distance')\n",
    "\n",
    "features = ['num__amt', 'num__city_pop', 'num__transaction_hour',\n",
    "       'num__transaction_day_of_week', 'num__transaction_month', \n",
    "       'num__age', 'cat__category', 'cat__gender', \n",
    "       'cat__city', 'cat__zip', 'cat__job']\n",
    "X_train_small_subset = X_train_small[features]\n",
    "X_test_subset = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "423c801c-1030-49e1-9005-f07432064c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Random Forest Classifier===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 1.0\n",
      "  Precision: 1.0\n",
      "  Recall: 1.0\n",
      "  F1 Score: 1.0\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9962403840592284\n",
      "  Precision: 0.6255969436485196\n",
      "  Recall: 0.8727514990006662\n",
      "  F1 Score: 0.7287899860917941\n",
      "\n",
      "Confusion Matrix:\n",
      "[[257050    784]\n",
      " [   191   1310]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.63      0.87      0.73      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.81      0.93      0.86    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "\n",
      "==========XGBoost===========\n",
      "\n",
      "Training Metrics:\n",
      "  Accuracy: 0.9993939893439087\n",
      "  Precision: 0.9996704308631803\n",
      "  Recall: 0.9991184049911841\n",
      "  F1 Score: 0.9993943416978782\n",
      "\n",
      "Testing Metrics:\n",
      "  Accuracy: 0.9978252067788768\n",
      "  Precision: 0.7719094602437608\n",
      "  Recall: 0.8860759493670886\n",
      "  F1 Score: 0.825062034739454\n",
      "\n",
      "Confusion Matrix:\n",
      "[[257441    393]\n",
      " [   171   1330]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    257834\n",
      "           1       0.77      0.89      0.83      1501\n",
      "\n",
      "    accuracy                           1.00    259335\n",
      "   macro avg       0.89      0.94      0.91    259335\n",
      "weighted avg       1.00      1.00      1.00    259335\n",
      "\n",
      "==========\n",
      "Best model is:  XGBoost\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifiers\n",
    "classifier = {\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(objective='multi:softmax', num_class=2),\n",
    "}\n",
    "\n",
    "best_precision_score = 0\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f\"\\n=========={name}===========\")\n",
    "    \n",
    "    clf.fit(X_train_small_subset, y_train_small)         # Train\n",
    "    y_train_pred = clf.predict(X_train_small_subset)     # Predict on training data\n",
    "    y_test_pred = clf.predict(X_test_subset)             # Predict on testing data\n",
    "    \n",
    "   \n",
    "    # Evaluation Metrics for Training Set\n",
    "    train_accuracy = accuracy_score(y_train_small, y_train_pred)\n",
    "    train_precision = precision_score(y_train_small, y_train_pred)\n",
    "    train_recall = recall_score(y_train_small, y_train_pred)\n",
    "    train_f1 = f1_score(y_train_small, y_train_pred)\n",
    "    \n",
    "    print(\"\\nTraining Metrics:\")\n",
    "    print(f\"  Accuracy: {train_accuracy}\")\n",
    "    print(f\"  Precision: {train_precision}\")\n",
    "    print(f\"  Recall: {train_recall}\")\n",
    "    print(f\"  F1 Score: {train_f1}\")\n",
    "    \n",
    "    # Evaluation Metrics for Testing Set\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(\"\\nTesting Metrics:\")\n",
    "    print(f\"  Accuracy: {test_accuracy}\")\n",
    "    print(f\"  Precision: {test_precision}\")\n",
    "    print(f\"  Recall: {test_recall}\")\n",
    "    print(f\"  F1 Score: {test_f1}\")\n",
    "    \n",
    "    # Confusion Matrix for Testing Set\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    \n",
    "    # Classification Report for Testing Set\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    if test_precision > best_precision_score:\n",
    "        best_precision_score = test_precision\n",
    "        best_model_name = name\n",
    "\n",
    "print(\"=\"*10)\n",
    "print(\"Best model is: \", best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cbb584b-7a8e-44f3-961b-3da93316d1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is:  XGBoost \n",
      " with Precision Score 0.7719094602437608\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model is: \", best_model_name, \"\\n with Precision Score\", best_precision_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31426e7c-ebb0-4897-ba77-f227f0cd6af9",
   "metadata": {},
   "source": [
    "### Comment:\n",
    "- ---> NO IMPROVEMENT with small feature subset of these 11 features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8fff17-7ce0-466a-8f5e-a78a86ae7d25",
   "metadata": {},
   "source": [
    "# 6. Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f708e7aa-5fd0-4242-9dbc-a50e6aa67fc6",
   "metadata": {},
   "source": [
    "According to experiments above, we can concluse that the best model for our dataset is XGBoost with full feature set (achieved Precision Score of  \n",
    " with Precision Score 0.7988) and XGBoost with 13 feature set (achieved Precision Score of 0.8027)\n",
    "\n",
    "- We will choose XGBoost algorithm to perform fine-tuning hyperparameter on our dataset in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff143f5f-38f9-4ff5-b9d9-1743a2141dc5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73c4db91-9d43-4b5a-a40f-2016071fe6f5",
   "metadata": {},
   "source": [
    "Thuy note: If after fine-tuning, the result doesn't get good, we need to consider as follows:\n",
    "- Keep long, lat, merch_long, merch_lat??? (instead of 'zip' and 'distance')\n",
    "- Incoporate Unsupervised Learning in order to add new feature named \"Anomaly_Cluster\" ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b421957-57bd-432a-9fe6-f7856f79aa08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
